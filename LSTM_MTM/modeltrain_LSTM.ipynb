{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# LSTM windowing and model training<br>\n", "# Authors: Juan Pablo Valdes and Fuyue Liang<br>\n", "# Code adapted from Fuyue Liang LSTM for stirred vessels<br>\n", "# First commit: Oct, 2023<br>\n", "# Department of Chemical Engineering, Imperial College London<br>\n", "#######################################################################################################################################################<br>\n", "#######################################################################################################################################################"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pickle\n", "import os,tempfile\n", "import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "import torch\n", "import random\n", "import numpy as np\n", "import torch.nn as nn\n", "import torch.optim as optim\n", "import torch.utils.data as data\n", "from torch.optim.lr_scheduler import ReduceLROnPlateau\n", "from tools_modeltraining import custom_loss, EarlyStopping\n", "import input as ipt\n", "from collections import namedtuple"]}, {"cell_type": "markdown", "metadata": {}, "source": [" For tuning"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from ray import train\n", "from ray.train import Checkpoint\n", "import ray.cloudpickle as raypickle"]}, {"cell_type": "markdown", "metadata": {}, "source": [" Env. variables ##"]}, {"cell_type": "markdown", "metadata": {}, "source": ["fig_savepath = '/Users/mfgmember/Documents/Juan_Static_Mixer/ML/LSTM_SMX/LSTM_MTM/figs/'<br>\n", "input_savepath = '/Users/mfgmember/Documents/Juan_Static_Mixer/ML/LSTM_SMX/LSTM_MTM/input_data/'<br>\n", "trainedmod_savepath = '/Users/mfgmember/Documents/Juan_Static_Mixer/ML/LSTM_SMX/LSTM_MTM/trained_models/'<br>\n", "tuningmod_savepath = '/Users/mfgmember/Documents/Juan_Static_Mixer/ML/LSTM_SMX/LSTM_MTM/tuning/'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ig_savepath = '/Users/juanpablovaldes/Documents/PhDImperialCollege/LSTM/LSTM_SMX/LSTM_MTM/figs/'<br>\n", "nput_savepath = '/Users/juanpablovaldes/Documents/PhDImperialCollege/LSTM/LSTM_SMX//LSTM_MTM/input_data/'<br>\n", "rainedmod_savepath = '/Users/juanpablovaldes/Documents/PhDImperialCollege/LSTM/LSTM_SMX/LSTM_MTM/trained_models'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig_savepath = '/home/fl18/Desktop/automatework/ML_casestudy/LSTM_SMX/LSTM_MTM/figs/'\n", "input_savepath = '/home/fl18/Desktop/automatework/ML_casestudy/LSTM_SMX/LSTM_MTM/input_data/'\n", "trainedmod_savepath = '/home/fl18/Desktop/automatework/ML_casestudy/LSTM_SMX/LSTM_MTM/trained_svmodels/'\n", "tuningmod_savepath = '/media/fl18/Elements/Hypertuning/'"]}, {"cell_type": "markdown", "metadata": {}, "source": [" Plot setup"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.rcParams.update({\n", "    \"text.usetex\": True,\n", "    \"font.family\": \"serif\",\n", "    \"font.serif\": ['Computer Modern']})"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["SMALL_SIZE = 8\n", "MEDIUM_SIZE = 12\n", "BIGGER_SIZE = 18\n", "plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n", "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n", "plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n", "plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n", "plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n", "plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n", "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fine_labels = {\n", "    # svcases #\n", "    'Bi0001': r'$Bi=0.001$', 'Bi0002': r'$Bi=0.002$', 'Bi0004': r'$Bi=0.004$', 'Bi001': r'$Bi=0.01$', 'Bi1': r'$Bi=1$',\n", "    'B05': r'$Bi=0.1, \\beta=0.5$','B07': r'$Bi=0.1, \\beta=0.7$', 'B09': r'$Bi=0.1, \\beta=0.9$',\n", "    'clean': r'Clean',\n", "    # smx cases #\n", "    'b03': r'$\\beta=0.3$','b06':r'$\\beta=0.6$','bi001':r'$Bi=0.01$','bi01':r'$Bi=0.1$','da01': r'$Da=0.1$','da1':r'$Da=1$',\n", "    'b06pm':r'$\\beta_{pm}=0.6$,','b09pm':r'$\\beta_{pm}=0.9$,','bi001pm':r'$Bi_{pm}=0.01$,',\n", "    'bi1':r'$Bi=1$','bi01pm':r'$Bi=0.1$,','3drop':r'3-Drop',\n", "    'b09':r'$\\beta=0.9$','da01pm':r'$Da_{pm}=0.1$, ','da001':r'$Da=0.01$', 'coarsepm':r'Pre-Mix'\n", "}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["################################### CLASSES #################################################"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Window_data():\n\n", "    ## split cases intro train, test and val data sets\n", "    def split_cases(self, df, train_frac, test_frac, cases):\n", "        '''\n", "        input shape: (times, cases, features)\n", "        \n", "        return train, val data and cases\n", "        '''\n", "        train_size = int(df.shape[1]*train_frac)\n", "        val_size = int(df.shape[1]*(1-test_frac-train_frac))\n", "        \n", "        # split data sets\n", "        train, val, test = df[:, :train_size, :], df[:, train_size:(train_size+val_size), :], df[:,(train_size+val_size):,:]\n", "        print(f'number of train, val and test cases: {train.shape[1]}, {val.shape[1]}, {test.shape[1]}')\n", "        \n", "        ## split cases grouped in three sets, labeled as train, val and test\n", "        train_cases, val_cases , test_cases = cases[:train_size], cases[train_size:(train_size+val_size)], cases[(train_size+val_size):]\n", "        print(f'training cases: {train_cases}, validation cases: {val_cases}, test cases: {test_cases}')\n", "            \n", "        return train, val, test, (train_cases, val_cases, test_cases)\n\n", "    ## plot split data sets   \n", "    def plot_split_cases(self, data, fine_labels, splitset_labels, train, val, test, \n", "                        features, case_labels, dpi=150):\n\n", "        #Plot setup\n", "        color_palettes = {\n", "        \"Training\": sns.color_palette(\"Set1\", len(case_labels)),\n", "        \"Validation\": sns.color_palette(\"Set2\", len(case_labels)),\n", "        \"Test\": sns.color_palette(\"Set3\", len(case_labels))\n", "    }\n", "        \n", "        train_cases = splitset_labels[0]\n", "        val_cases = splitset_labels[1]\n", "        test_cases = splitset_labels[2]\n\n", "        ## Looping over all three data sets\n", "        for split_set, label in zip([train, val, test], \n", "                                    ['Training', 'Validation', 'Test']):\n", "            \n", "            case_labels = train_cases if label == \"Training\" else val_cases if label == \"Validation\" else test_cases\n", "            if len(features) > 1:\n", "                fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n", "                color_palette = color_palettes[label]\n", "            \n", "                for axis in ax:\n", "                    for spine in axis.spines.values():\n", "                        spine.set_linewidth(1.5)\n", "                ## Looping per feature number in each split set\n", "                for i in range(data.shape[-1]):\n", "                    for idx, case in enumerate(case_labels):\n", "                        plot_label = fine_labels.get(case,case)\n", "                        ax[i].plot(split_set[:,idx,i],label = f'{plot_label}',color=color_palette[idx % len(color_palette)])\n", "                        ax[i].set_title(f'{label}: {features[i]}')\n", "                        ax[i].set_xlabel('Time steps')\n", "                        ax[i].set_ylabel(f'Scaled {features[i]}')\n", "                        ax[i].tick_params(bottom=True, top=True, left=True, right=True,axis='both',direction='in', length=5, width=1.5)\n", "                        ax[i].grid(color='k', linestyle=':', linewidth=0.1)\n", "                        ax[i].legend()\n", "                ## saving figures\n", "                fig.savefig(os.path.join(fig_savepath, f'{label}_data_{features[i]}.png'), dpi=dpi)\n", "            \n", "            else:\n", "                fig,ax = plt.plot(figsize=(12,5))\n", "                color_palette = color_palettes[label]\n", "                for spine in ax.spines.values():\n", "                    spine.set_linewidth(1.5)\n", "                for idx, case in enumerate(case_labels):\n", "                    plot_label = fine_labels.get(case,case)\n", "                    ax.plot(split_set[:,idx,0],label = f'{plot_label}',color=color_palette[idx % len(color_palette)])\n", "                    ax.set_title(f'{label}: {features[0]}')\n", "                    ax.set_xlabel('Time steps')\n", "                    ax.set_ylabel(f'Scaled {features[0]}')\n", "                    ax.tick_params(bottom=True, top=True, left=True, right=True,axis='both',direction='in', length=5, width=1.5)\n", "                    ax.grid(color='k', linestyle=':', linewidth=0.1)\n", "                    ax.legend()\n", "                ## saving figures\n", "                fig.savefig(os.path.join(fig_savepath, f'{label}_data_{features[0]}.png'), dpi=dpi)\n", "            plt.show()\n\n", "    ## Generate windows from input data\n", "    def window_data(self, df, steps_in, stride, steps_out):\n", "        '''\n", "        \n", "        df: with shape (times, cases, features)\n", "        stride: the step size between consecutive windows\n", "        pred_times:(<window_size) predicted future times from current window\n", "        window size: Encompasses both steps_in and steps_out, referring to input seq and prediction seq\n", "        \n", "        lookback period = window_size - steps_out = steps in\n", "        \n", "        '''\n", "        window_size = steps_in + steps_out\n", "        casebatch_lens = [] # List to contain the number of rows/windows per case used for input-->prediction based on the steps_in - steps_out parameters\n", "                            # Can be calculated as: len(timesteps)-window_size+1\n", "        X, y = [], []\n", "        for i in range(df.shape[1]): # looping for each case, df shape of (times, cases, features)\n", "            df_case = df[:,i,:] # df per case\n", "            for j in range(0, df_case.shape[0]-window_size+1, stride): # Looping over number of rows/windows, depending on window size and number of timesteps (df.shape[0])\n", "                wd_data = df_case[j:j+window_size] # window with times: steps_in + steps_out: entire row\n", "                X.append(wd_data[:-steps_out]) #input values, steps_in\n", "                y.append(wd_data[-steps_out:]) #training/ prediction values, steps_out\n", "            casebatch_lens.append(len(X)) # appending casebatch length per case \n\n", "        ## number of windows/rows with size (steps_in) per case, used to later plot per case\n", "        print(casebatch_lens)\n", "        X_array = np.array(X)\n", "        y_array = np.array(y)\n", "        \n", "        return torch.tensor(X_array), torch.tensor(y_array), np.array(casebatch_lens)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class LSTM_DMS(nn.Module):\n", "    \n", "    ## class constructor\n", "    def __init__(self, input_size, hidden_size, output_size, pred_steps,\n", "                 l1_lambda=0.0, l2_lambda=0.0):\n", "        \n", "        # calling the constructor of the parent class nn.Module to properly intialize this class\n", "        super(LSTM_DMS,self).__init__()\n\n", "        #LSTM attributes\n", "        self.hidden_size = hidden_size\n", "        self.pred_steps = pred_steps # prediction steps = steps_out\n", "        self.output_size = output_size # number of features per output step.\n", "        ## LSTM unit/cell instance from parent class\n", "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True) \n", "        # Linear/dense layer instance from parent class, for decoding multi-step predictions\n", "        self.linear = nn.Linear(hidden_size, output_size * pred_steps)\n\n", "        # Relevance markers for L1 and L2 regularizations\n", "        self.l1_lambda = l1_lambda\n", "        self.l2_lambda = l2_lambda\n\n", "    ### forward pass: How input data will be processed by the network layers\n", "    def forward(self, input):\n\n", "        # No initialisation for hidden or cell states h0, c0. \n", "        # Inputting data (x_set) into the LSTM cell sequence and reading the output per unit/cell and as a whole at the end\n", "        lstm_output, _ = self.lstm(input)#,(h0,c0)) #shape as (batch_size, input_steps, hidden states)\n", "        \n", "        # Get the hidden state from the last input step given to the LSTM sequence\n", "        last_output = lstm_output[:, -1, :]\n", "        \n", "        # Input the last output from the LSTM sequence into the dense linear layer, where we obtain the multi-output\n", "        multi_step_output = self.linear(last_output)\n", "        \n", "        # Reshape the output to get predictions for multiple future time steps\n", "        multi_step_output = multi_step_output.view(-1, self.pred_steps, self.output_size)\n", "        return multi_step_output\n", "    \n", "    ### Regularization functions to prevent overfitting\n", "    #L1 (lasso) encourages sparse weights\n", "    def l1_regularization_loss(self):\n", "        if self.training:\n", "            l1_loss = 0.0\n", "            for param in self.parameters():\n", "                l1_loss += torch.sum(torch.abs(param))\n", "            return self.l1_lambda * l1_loss\n", "        else:\n", "            return 0\n\n", "    #L2 (Ridge) encourages small weights\n", "    def l2_regularization_loss(self):\n", "        if self.training:\n", "            l2_loss = 0.0\n", "            for param in self.parameters():\n", "                l2_loss += torch.sum(param ** 2)\n", "            return 0.5 * self.l2_lambda * l2_loss\n", "        else:\n", "            return 0"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class LSTM_encoder(nn.Module):\n\n", "    # Same as LSTM DMS constructor but with no pred_steps or linear layer as encoder feeds decoder LSTM through the hidden states\n", "    def __init__(self,input_size,hidden_size, num_layers=1):\n", "        super(LSTM_encoder,self).__init__()\n", "        self.input_size = input_size\n", "        self.hidden_size = hidden_size\n", "        self.num_layers = num_layers\n", "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, \n", "                            batch_first=True)\n", "        \n", "    # Take the input sequences and output the hidden states for the LSTM decoder section\n", "    def forward(self, encoder_input):\n", "        ''' \n", "        return encoder_hidden_states: outputs the last time hidden and cell state to be fed into the LSTM decoder\n", "        \n", "        input shape: (batch_size, input steps/input window, input_size=num_features)\n", "        output shape: (input_size=num_features, hidden_size)\n", "        '''\n", "        _, (h_n_encoder,c_n_encoder) = self.lstm(encoder_input) # ignoring output (hidden states) for all times and only saving a tuple with the last timestep cell and hidden state\n", "        \n", "        return (h_n_encoder,c_n_encoder)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class LSTM_decoder(nn.Module):\n\n", "    ## Same constructor as DMS as now we are decoding the final LSTM cell through a linear layer to generate the final output \n", "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n", "        super(LSTM_decoder, self).__init__()\n", "        self.input_size = input_size\n", "        self.hidden_size = hidden_size\n", "        self.output_size = output_size\n", "        self.num_layers = num_layers\n", "        \n", "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, \n", "                            batch_first=True)\n", "        \n", "        self.linear = nn.Linear(hidden_size, output_size)\n", "    def forward(self, decoder_input, encoder_states):\n", "        '''\n", "        return \n", "        lstm_output: returns decoded hidden states as output for all times \n", "        \n", "        input shape: (batch_size, 1, input_size=num_features) the last time step\n", "        output shape: (batch_size, input_size=num_features)\n", "        '''\n\n", "        # LSTM cell is initialized with the encoder cell and hidden states\n", "                # Input tensor is unsqueezed to introduce an additional dimension in axis = 1 to perform LSTM calculations normally for 1 step\n", "        lstm_output, _ = self.lstm(decoder_input.unsqueeze(1), encoder_states) #Similar to DMS, output is saved, representing all hidden states per timestep\n", "        \n", "        ## output tensor is squeezed, removing the aritificial time dimension in axis = 1, as it will be looped during prediction for each time and appended to a 3D tensor.\n", "        output = self.linear(lstm_output.squeeze(1))\n", "        \n", "        return output\n", "    \n", "class LSTM_S2S(nn.Module):\n", "    ''' Double LSTM Encoder-decoder architecture to make predictions '''\n\n", "    #Constructing the encoder decoder LSTM architecture\n", "    def __init__(self, input_size, hidden_size, output_size, pred_steps,\n", "                 l1_lambda=0.0, l2_lambda=0.0):\n", "        super(LSTM_S2S,self).__init__()\n", "        self.input_size = input_size\n", "        self.hidden_size = hidden_size\n", "        self.output_size = output_size\n", "        self.pred_steps = pred_steps #steps out = output window\n\n", "        # Relevance markers for L1 and L2 regularizations\n", "        self.l1_lambda = l1_lambda\n", "        self.l2_lambda = l2_lambda\n", "        \n", "        self.encoder = LSTM_encoder(input_size=input_size, hidden_size=hidden_size)\n", "        self.decoder = LSTM_decoder(input_size=input_size, hidden_size=hidden_size, output_size=output_size)\n", "    def forward(self,input_tensor):\n", "        '''\n", "        input_tensor: shape (batch_size, input steps = input window, input_size=num_features)\n", "        pred_steps: number of time steps to predict\n", "        return np_outputs: array containing predictions\n", "        '''\n", "                \n", "        # encode input_tensor\n", "        encoder_states = self.encoder(input_tensor)\n\n", "        # initialize output tensor for prediction\n", "        outputs = torch.zeros(input_tensor.shape[0], self.pred_steps, input_tensor.shape[2]) #shape = batch_size, steps_out, num_features\n\n", "        # decode input_tensor\n", "        decoder_input = input_tensor[:,-1,:] # Taking last value in the window/sequence\n", "        decoder_input_states = encoder_states\n\n", "        # predictions carried out on the decoder for each time in the output window = steps_out\n", "        for t in range(self.pred_steps):\n", "            decoder_output = self.decoder(decoder_input,decoder_input_states)\n", "            outputs[:,t,:] = decoder_output\n", "            # prediction done recursively\n", "            decoder_input = decoder_output\n", "        np_outputs = outputs.detach().numpy() ## detaching from gradient requirements during prediction\n", "        return torch.from_numpy(np_outputs)\n", "    \n", "    ### Regularization functions to prevent overfitting\n", "    #L1 (lasso) encourages sparse weights\n", "    def l1_regularization_loss(self):\n", "        if self.training:\n", "            l1_loss = 0.0\n", "            for param in self.parameters():\n", "                l1_loss += torch.sum(torch.abs(param))\n", "            return self.l1_lambda * l1_loss\n", "        else:\n", "            return 0\n\n", "    #L2 (Ridge) encourages small weights\n", "    def l2_regularization_loss(self):\n", "        if self.training:\n", "            l2_loss = 0.0\n", "            for param in self.parameters():\n", "                l2_loss += torch.sum(param ** 2)\n", "            return 0.5 * self.l2_lambda * l2_loss\n", "        else:\n", "            return 0"]}, {"cell_type": "markdown", "metadata": {}, "source": ["################################### INPUT_DATA FUN. ################################################"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def input_data(svcases, features,smoothing_method):\n", " \n", "    # scaled input data \n", "    post_dict = ipt.scale_inputs(svcases,features)\n\n", "    # re-shaped input data\n", "    shaped_input = ipt.shape_inputdata(post_dict)\n\n", "    #plotting\n", "    ipt.plot_inputdata(svcases,fine_labels,shaped_input)\n\n", "    # smoothing data\n", "    smoothed_data = ipt.smoothing(shaped_input,smoothing_method,window_size=5,poly_order=3,lowess_frac=0.03)\n", "    ipt.plot_smoothdata(shaped_input, smoothed_data,fine_labels, smoothing_method, svcases)\n\n", "    ## saving input data \n", "    with open(os.path.join(input_savepath,'svinputdataDSD.pkl'),'wb') as file:\n", "        pickle.dump(smoothed_data,file)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["################################### WINDOWING FUN. #################################################"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def windowing(steps_in,steps_out,stride,train_frac,test_frac,svcases, features):\n", "    ## Class instance declarations:\n", "    windowing = Window_data()\n\n", "    ## namedtuple used to return all data arrays\n", "    WindowedData = namedtuple('WindowedData', [\n", "    'X_train', 'y_train', 'train_casebatch',\n", "    'X_val', 'y_val', 'val_casebatch',\n", "    'train_arr', 'val_arr', 'test_arr', 'splitset_labels'\n", "    ])\n\n", "    # Reading saved re-shaped input data from file\n", "    with open(os.path.join(input_savepath,'svinputdataDSD.pkl'), 'rb') as file:\n", "        input_df = pickle.load(file)\n", "    \n", "    input_df = np.transpose(input_df,(1,0,2)).astype('float32')\n", "    train_arr, val_arr, test_arr, splitset_labels = windowing.split_cases(\n", "        input_df, train_frac, test_frac, svcases)\n", "    \n", "    ## plotting split data\n", "    plot_choice = input('plot split data sets? (y/n) :')\n", "    if plot_choice.lower() == 'y' or plot_choice.lower() == 'yes':\n", "        windowing.plot_split_cases(input_df, fine_labels, splitset_labels, train_arr, val_arr, test_arr, \n", "                            features,svcases)\n", "    else:\n", "        pass"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    #Windowed training data\n", "    X_train, y_train, train_casebatch = windowing.window_data(train_arr, steps_in, stride, steps_out)\n", "    #Windowed validation data\n", "    X_val, y_val, val_casebatch = windowing.window_data(val_arr, steps_in, stride, steps_out)\n", "    print(f\"Windowed input training data shape: {X_train.shape}\")\n", "    print(f\"Windowed output training shape: {y_train.shape}\")\n", "    print(f\"Windowed input validation data shape: {X_val.shape}\")\n", "    print(f\"Windowed output validation shape: {y_val.shape}\")\n", "    return WindowedData(\n", "        X_train=X_train, y_train=y_train, train_casebatch=train_casebatch,\n", "        X_val=X_val, y_val=y_val, val_casebatch=val_casebatch,\n", "        train_arr=train_arr, val_arr=val_arr, test_arr=test_arr,\n", "        splitset_labels=splitset_labels\n", "    )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["##################################### SAVING FUN. ##################################################"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def saving_data(wd,hp,model_choice,save_hp=True):\n", "    \n", "    set_labels = [\"train\", \"val\", \"test\"]\n", "    arrays = [wd.train_arr, wd.val_arr, wd.test_arr]\n", "    input_tensors = [wd.X_train, wd.X_val]\n", "    out_tensors = [wd.y_train, wd.y_val]\n", "    casebatches = [wd.train_casebatch,wd.val_casebatch]\n\n", "    ## saving train, validation and test data sets previously split and used as input for windowing process, with corresponding labels\n", "    for setlbl, arr, caselbl_list in zip(set_labels, arrays, wd.splitset_labels):\n", "        save_dict = {\n", "        f\"{setlbl}_arr\": arr,\n", "        \"splitset_labels\": caselbl_list\n", "    }\n", "        with open(os.path.join(trainedmod_savepath,f'data_sets_{model_choice}', f'{setlbl}_pkg.pkl'), 'wb') as file:\n", "            pickle.dump(save_dict, file)\n", "        print(f\"Saved split set data and labels {setlbl}_pkg.pkl\")\n\n", "    ## saving windowed train and validation datasets (pytorch tensors), with corresponding casebatch lengths  \n", "    for setlbl, in_tens, out_tens, csbatch in zip(set_labels, input_tensors, out_tensors, casebatches):\n", "        \n", "        save_indict = {\n", "        \"windowed_data\": in_tens,\n", "        f\"{setlbl}_casebatch\": csbatch\n", "        }\n", "        save_outdict = {\n", "        \"windowed_data\": out_tens,\n", "        f\"{setlbl}_casebatch\": csbatch\n", "        }\n", "        file_in = os.path.join(trainedmod_savepath,f'data_sets_{model_choice}', f'X_{setlbl}.pt')\n", "        file_out = os.path.join(trainedmod_savepath,f'data_sets_{model_choice}', f'y_{setlbl}.pt')\n", "        torch.save(save_indict, file_in)\n", "        torch.save(save_outdict, file_out)\n", "        print(f\"Saved torch package X_{setlbl}.pt\")\n", "        print(f\"Saved torch package y_{setlbl}.pt\")\n", "    \n", "    ## save hyperparameters used for model trained for later plotting and rollout prediction\n", "    if save_hp:\n", "        hyperparams = {\n", "            \"input_size\": hp.input_size,\n", "            \"hidden_size\": hp.hidden_size,\n", "            \"output_size\": hp.output_size,\n", "            \"pred_steps\": hp.pred_steps,\n", "            \"batch_size\": hp.batch_size,\n", "            \"learning_rate\": hp.learning_rate,\n", "            \"num_epochs\": hp.num_epochs,\n", "            \"check_epochs\": hp.check_epochs,\n", "            \"steps_in\": hp.steps_in,\n", "            \"steps_out\": hp.steps_out,\n", "            \"tf_ratio\": hp.tf_ratio,\n", "            \"dynamic_tf\": hp.dynamic_tf\n", "        }\n", "        with open(os.path.join(trainedmod_savepath,f'hyperparams_{model_choice}.txt'), \"w\") as file:\n", "            for key, value in hyperparams.items():\n", "                file.write(f\"{key}: {value}\\n\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["##################################### TRAINING FUN. #################################################"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train_DMS(model, optimizer, loss_fn, trainloader, valloader, scheduler,\n", "                  num_epochs, check_epochs, \n", "                  X_train, y_train, X_val, y_val, device,saveas,\n", "                  batch_loss = False,tuning=False):\n", "    \n", "    model_name = 'DMS'\n", "    with open(str(saveas)+'.txt', 'w') as f:\n", "        print(model, file=f)\n\n", "        ## If a checkpoint state is going to be further trained (e.g., from Ray Tune parametric sweep)\n", "        if tuning:\n", "            # Get checkpoint from Ray train feature\n", "            loaded_checkpoint = train.get_checkpoint()\n", "            if loaded_checkpoint:\n", "                with loaded_checkpoint.as_directory() as loaded_checkpoint_dir:\n", "                    with open(os.path.join(loaded_checkpoint_dir, 'chk_dict.pkl'),'rb') as fp:\n", "                        loaded_checkpoint_state = raypickle.load(fp)\n", "                        \n", "                        model.load_state_dict(loaded_checkpoint_state['model_state_dict'])\n", "                        optimizer.load_state_dict(loaded_checkpoint_state['optimizer_state_dict'])\n", "        else:\n", "            ### Early stopping feature to avoid overfitting during training, monitoring a minimum improvement threshold\n", "            early_stopping = EarlyStopping(model_name,patience=10, verbose=True)\n", "        for epoch in range(num_epochs): #looping through epochs\n", "            model.train() #set the model to train mode -- informing features to behave accordingly for training\n", "            \n", "            first_iteration = True\n", "            for X_batch, y_batch in trainloader:\n", "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n", "                optimizer.zero_grad() # setting gradients to zero to start a new run on weight optimisation (clear accumulated from previous batch)\n", "                # Forward pass\n", "                y_pred = model(X_batch).to(device)\n", "                # Calculate loss\n", "                loss = loss_fn(y_pred, y_batch).to(device)\n", "                # Calculate L1 and L2 regularization terms\n", "                l1_regularization = model.l1_regularization_loss()\n", "                l2_regularization = model.l2_regularization_loss()\n", "                # Add regularization terms to the loss\n", "                loss += l1_regularization + l2_regularization\n", "                # Backpropagation and parameter update\n", "                loss.backward() # calculating the gradient of the loss with respect to the model's parameters (weights and biases)\n", "                                # it acculmulates the gradients each time we go through the nested loop\n", "                optimizer.step() # updating parameters to minimize the loss function\n", "                # Check the shapes in the first iteration of the first epoch\n", "                if epoch == 0 and first_iteration:\n", "                    print('Input shape:', X_batch.shape)\n", "                    print('Output shape:', y_pred.shape)\n", "                    first_iteration = False\n\n", "            # Validation at each check epoch batch\n", "            if epoch % check_epochs != 0:\n", "                continue\n", "            model.eval() # set the model to evaluation form, disabling regularisation and training features\n", "            with torch.no_grad():  # Predictions performed with no gradient calculations        \n", "                ## Checking if we want to compute model loss in a staggered (minibatch) manner\n", "                if batch_loss:\n", "                    train_loss = 0\n", "                    val_loss = 0\n", "                    steps_train = 0\n", "                    steps_val = 0\n", "                    ## calculating loss per batch and accumulating\n", "                    for traindata in trainloader:\n", "                        X_trbatch, y_trbatch = traindata.to(device)\n", "                        tr_output = model(X_trbatch).to(device)\n", "                        lss1 = loss_fn(tr_output, y_trbatch).to(device)\n", "                        train_loss += lss1.numpy()\n", "                        steps_train += 1\n", "                    for valdata in valloader:\n", "                        X_valbatch, y_valbatch = valdata.to(device)\n", "                        val_output = model(X_valbatch).to(device)\n", "                        lss2 = loss_fn(val_output, y_valbatch).to(device)\n", "                        val_loss += lss2.numpy()\n", "                        steps_val += 1\n", "                    # Arithmetic average based on the number of batches per train/val loader\n", "                    t_rmse = train_loss / steps_train\n", "                    v_rmse = val_loss / steps_val\n", "                \n", "                ## Single loss over entire validation data set.\n", "                else:\n", "                    y_pred_train = model(X_train).to(device)\n", "                    y_pred_val = model(X_val).to(device)\n", "                    t_rmse = loss_fn(y_pred_train, y_train).to(device)\n", "                    v_rmse = loss_fn(y_pred_val, y_val).to(device)\n", "                print('Epoch %d : train RMSE  %.4f, val RMSE %.4f ' % (epoch, t_rmse, v_rmse), file=f)\n", "                print('Epoch %d : train RMSE  %.4f, val RMSE %.4f ' % (epoch, t_rmse, v_rmse))\n", "                \n", "            ## If in tuning mode, save checkpoint for model and optimizer state, and register checkpoint with train.report.\n", "            if tuning:\n", "                with tempfile.TemporaryDirectory() as checkpoint_dir:\n", "                    with open(os.path.join(checkpoint_dir, 'chk_dict.pkl'), 'wb') as fp:\n", "                        raypickle.dump({'epoch': epoch,\n", "                                     'model_state_dict': model.state_dict(),\n", "                                     'optimizer_state_dict': optimizer.state_dict()},fp)\n", "                        \n", "                    checkpoint = Checkpoint.from_directory(os.path.join(checkpoint_dir))\n", "                    train.report({\"val_loss\": v_rmse, \"train_loss\": t_rmse}, checkpoint=checkpoint)\n", "            else:\n", "                ## Learning rate scheduler step\n", "                scheduler.step(v_rmse)\n", "                ## early stopping check to avoid overfitting\n", "                early_stopping(v_rmse, model)\n", "                if early_stopping.early_stop:\n", "                    print('Early stopping')\n", "                    break\n", "    print('Finished training')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train_S2S(model, optimizer, loss_fn, trainloader,valloader,scheduler, num_epochs, \n", "              check_epochs, pred_steps, X_train, y_train, X_val, y_val, \n", "              tf_ratio, dynamic_tf,training_prediction,device, saveas,\n", "              batch_loss=False,tuning=False):\n", "    ''' \n", "    training_prediction: ('recursive'/'teacher_forcing'/'mixed')\n", "    tf_ratio: float[0,1] \n", "                relevance on teacher forcing when training_prediction = 'teacher_forcing'.\n", "                For each batch, a random number is generated. \n", "                If the number is less than tf_ratio, tf is used; otherwise, prediction is done recursively.\n", "                If tf_ratio = 1, only tf is used.\n", "    dynamic_tf: (True/False)\n", "                dynamic teacher forcing reduces the amount of teacher forcing for each epoch\n", "    \n", "    return loss: array of loss function for each epoch\n", "    '''\n", "    model_name = 'S2S'\n\n", "    # save the training model\n", "    with open(str(saveas)+'.txt', 'w') as f:\n", "        print(model, file=f)\n\n", "        ## If a checkpoint state is going to be further trained (e.g., from Ray Tune parametric sweep)\n", "        if tuning:\n", "            # Get checkpoint from Ray train feature\n", "            loaded_checkpoint = train.get_checkpoint()\n", "            if loaded_checkpoint:\n", "                with loaded_checkpoint.as_directory() as loaded_checkpoint_dir:\n", "                    with open(os.path.join(loaded_checkpoint_dir, 'chk_dict.pkl'),'rb') as fp:\n", "                        loaded_checkpoint_state = raypickle.load(fp)\n", "                        \n", "                        model.load_state_dict(loaded_checkpoint_state['model_state_dict'])\n", "                        optimizer.load_state_dict(loaded_checkpoint_state['optimizer_state_dict'])\n", "        else:\n", "            ### Early stopping feature to avoid overfitting during training, monitoring a minimum improvement threshold\n", "            early_stopping = EarlyStopping(model_name,patience=10, verbose=True)\n", "        for epoch in range(num_epochs): #looping through training epochs\n", "            \n", "            model.train() #setting model to training function to deactivate regularization and other training features\n", "            first_iteration = True\n", "            for X_batch, y_batch in trainloader:\n", "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n", "                # initializing output tensor\n", "                outputs = torch.zeros(X_batch.shape[0], pred_steps, X_batch.shape[2]).to(device) #shape = (batch_size,steps_out,num_features)\n", "                #reset gradients from previous training step\n", "                optimizer.zero_grad()\n", "                #going through the LSTM encoder layer: return hidden and cell states\n", "                encoder_states = model.encoder(X_batch)\n", "                # decoder starting with teacher forcing: input set as last timestep from input batch\n", "                decoder_input = X_batch[:,-1,:] # in shape of (batch_size, input_size = num_features)\n", "                decoder_input_states = encoder_states\n", "                #Considering variations in training methods per batch\n", "                if training_prediction == 'recursive':\n", "                        \n", "                    # recursive prediction: predicted output is fed\n", "                        for t in range(pred_steps):\n", "                            decoder_output = model.decoder(decoder_input, decoder_input_states)\n", "                            outputs[:,t,:] = decoder_output\n", "                            decoder_input = decoder_output"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["                if training_prediction == 'teacher_forcing':\n", "                        \n", "                    # predict using teacher forcing: target is fed\n", "                        if random.random() < tf_ratio:\n", "                            for t in range(pred_steps):\n", "                                decoder_output = model.decoder(decoder_input, decoder_input_states)\n", "                                outputs[:,t,:] = decoder_output\n", "                                decoder_input = y_batch[:,t,:] # target fed from y_batch in shape of (batch_size, input_size = num_features)\n", "                        # predict recursively\n", "                        else:\n", "                            for t in range(pred_steps):\n", "                                decoder_output = model.decoder(decoder_input, decoder_input_states)\n", "                                outputs[:,t,:] = decoder_output\n", "                                decoder_input = decoder_output"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["                if training_prediction == 'mixed':\n", "                    # both types of training methods used in the same batch, alternating stochastically based on tf_ratio\n", "                    for t in range(pred_steps):\n", "                        decoder_output = model.decoder(decoder_input, decoder_input_states)\n", "                        outputs[:,t,:] = decoder_output\n", "                        ## Teaching method chosen per timestep within the given batch\n", "                        # teacher forcing\n", "                        if random.random() < tf_ratio:\n", "                            decoder_input = y_batch[:,t,:]\n", "                        # recursive:\n", "                        else:\n", "                            decoder_input = decoder_output\n", "                loss = loss_fn(outputs,y_batch).to(device)\n", "                # Calculate L1 and L2 regularization terms\n", "                l1_regularization = model.l1_regularization_loss()\n", "                l2_regularization = model.l2_regularization_loss()\n", "                # Add regularization terms to the loss\n", "                loss += l1_regularization + l2_regularization\n", "                # Backpropagation and parameter update\n", "                loss.backward() # calculating the gradient of the loss with respect to the model's parameters (weights and biases)\n", "                                # it acculmulates the gradients each time we go through the nested loop\n", "                optimizer.step() # updating parameters to minimize the loss function\n", "                # Check the shapes in the first iteration of the first epoch\n", "                if epoch == 0 and first_iteration:\n", "                    print('Input shape:', X_batch.shape)\n", "                    print('Output shape:', outputs.shape)\n", "                    first_iteration = False\n", "                \n", "            # dynamic teacher forcing\n", "            if dynamic_tf and tf_ratio > 0:\n", "                tf_ratio = tf_ratio - 0.02 ## if dynamic tf active, the amount of teacher forcing is reduced per epoch\n\n", "            # Validation at each check epoch batch\n", "            if epoch % check_epochs != 0:\n", "                continue\n", "            model.eval() # set the model to evaluation form, disabling regularisation and training features\n", "            with torch.no_grad():  # Predictions performed with no gradient calculations        \n", "                ## Checking if we want to compute model loss in a staggered (minibatch) manner\n", "                if batch_loss:\n", "                    train_loss = 0\n", "                    val_loss = 0\n", "                    steps_train = 0\n", "                    steps_val = 0\n", "                    ## calculating loss per batch and accumulating\n", "                    for traindata in trainloader:\n", "                        X_trbatch, y_trbatch = traindata.to(device)\n", "                        tr_output = model(X_trbatch).to(device)\n", "                        lss1 = loss_fn(tr_output, y_trbatch).to(device)\n", "                        train_loss += lss1.numpy()\n", "                        steps_train += 1\n", "                    for valdata in valloader:\n", "                        X_valbatch, y_valbatch = valdata.to(device)\n", "                        val_output = model(X_valbatch).to(device)\n", "                        lss2 = loss_fn(val_output, y_valbatch).to(device)\n", "                        val_loss += lss2.numpy()\n", "                        steps_val += 1\n", "                    # Arithmetic average based on the number of batches per train/val loader\n", "                    t_rmse = train_loss / steps_train\n", "                    v_rmse = val_loss / steps_val\n", "                \n", "                ## Single loss over entire validation data set.\n", "                else:\n", "                    y_pred_train = model(X_train).to(device)\n", "                    y_pred_val = model(X_val).to(device)\n", "                    t_rmse = loss_fn(y_pred_train, y_train).to(device)\n", "                    v_rmse = loss_fn(y_pred_val, y_val).to(device)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["                print('Epoch %d : train RMSE  %.4f, val RMSE %.4f ' % (epoch, t_rmse, v_rmse), file=f)\n", "                print('Epoch %d : train RMSE  %.4f, val RMSE %.4f ' % (epoch, t_rmse, v_rmse))\n", "                \n", "            ## If in tuning mode, save checkpoint for model and optimizer state, and register checkpoint with train.report.\n", "            if tuning:\n", "                with tempfile.TemporaryDirectory() as checkpoint_dir:\n", "                    with open(os.path.join(checkpoint_dir, 'chk_dict.pkl'), 'wb') as fp:\n", "                        raypickle.dump({'epoch': epoch,\n", "                                     'model_state_dict': model.state_dict(),\n", "                                     'optimizer_state_dict': optimizer.state_dict()},fp)\n", "                        \n", "                    checkpoint = Checkpoint.from_directory(os.path.join(checkpoint_dir))\n", "                    train.report({\"val_loss\": v_rmse, \"train_loss\": t_rmse}, checkpoint=checkpoint)\n", "            else:\n", "                ## Learning rate scheduler step\n", "                scheduler.step(v_rmse)\n", "                ## early stopping check to avoid overfitting\n", "                early_stopping(v_rmse, model)\n", "                if early_stopping.early_stop:\n", "                    print('Early stopping')\n", "                    break\n", "                \n", "    print('Finished training')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["######################################### MAIN ########################################################"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def main():\n\n", "    ####### WINDOW DATA ########\n\n", "    ## Windowing hyperparameters\n", "    steps_in, steps_out = 50, 50\n", "    stride = 1\n\n", "    ## Cases to split and features to read from \n", "    # Allcases = ['b03','b06','bi001','bi01','da01','da1','b06pm','b09pm','bi001pm',\n", "    # 'bi1','bi01pm','3drop',\n", "    # 'b09','da01pm','da001', 'coarsepm']\n", "    svcases = ['Bi0001','Bi0004','Bi001','B05','B07','clean','B09','Bi1','Bi0002']\n", "    features = ['Number of drops', 'Interfacial Area'] # 'Estimated Density of drop counts in one bin'\n", "    smoothing_method = 'lowess'\n\n", "    # input_data(svcases,features,smoothing_method)\n\n", "    ## data splitting for training, validating and testing\n", "    train_frac = 0.7\n", "    test_frac = 0.15\n", "    windowed_data = windowing(steps_in,steps_out,stride,train_frac, test_frac, svcases,features)\n\n", "    ## Extracting from named tuple\n", "    X_train = windowed_data.X_train.to(torch.float32).to(device)\n", "    y_train = windowed_data.y_train.to(torch.float32).to(device)\n", "    X_val = windowed_data.X_val.to(torch.float32).to(device)\n", "    y_val = windowed_data.y_val.to(torch.float32).to(device)\n\n", "    ######### LSTM MODEL TRAINING ##########\n", "    \n", "    # check if GPU is available\n", "    if torch.cuda.is_available():\n", "        device = torch.device(\"cuda\")\n", "        print(\"Training is now on CUDA.\")\n", "    else:\n", "        device = torch.device(\"cpu\") \n\n", "    # Define hyperparameters\n", "    input_size = X_train.shape[-1]  # Number of features in the input tensor\n", "    hidden_size = 128  # Number of hidden units in the LSTM cell, determines how many weights will be used in the hidden state calculations\n", "    output_size = y_train.shape[-1]  # Number of output features, same as input in this case\n", "    pred_steps = steps_out # Number of future steps to predict\n", "    batch_size = 30 # How many windows are being processed per pass through the LSTM\n", "    learning_rate = 0.005\n", "    num_epochs = 2000\n", "    check_epochs = 100\n", "    tf_ratio = 0.1\n", "    dynamic_tf = True\n\n", "    # customize loss function \n", "    penalty_weight = 10\n", "    loss_fn = custom_loss(penalty_weight).to(device)\n", "    trainloader = data.DataLoader(data.TensorDataset(X_train, y_train), shuffle=True, batch_size=batch_size)\n", "    valloader = data.DataLoader(data.TensorDataset(X_val, y_val), shuffle=True, batch_size=batch_size)\n", "        \n", "    ## Calling model class instance and training function\n", "    model_choice = input('Select a LSTM model to train (DMS, S2S): ')\n", "    if model_choice == 'DMS':\n", "        # LSTM model instance\n", "        model = LSTM_DMS(input_size, hidden_size, output_size, pred_steps,\n", "                            l1_lambda=0.00, l2_lambda=0.00)\n", "        \n", "        model.to(device)\n", "        \n", "        optimizer = optim.Adam(model.parameters(), lr = learning_rate) # optimizer to estimate weights and biases (backpropagation)\n", "            \n", "        # Learning rate scheduler, set on min mode to decrease by factor when validation loss stops decreasing                                       \n", "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n", "        \n", "        train_DMS(model, optimizer, loss_fn, trainloader, valloader, scheduler, \n", "            num_epochs, check_epochs, X_train, y_train, X_val, \n", "            y_val,device=device,saveas='DMS_out',batch_loss=False)\n", "        \n", "    elif model_choice == 'S2S':\n", "        # LSTM model instance\n", "        model = LSTM_S2S(input_size, hidden_size, output_size, pred_steps,\n", "                         l1_lambda=0.00, l2_lambda=0.00)\n", "        \n", "        model.to(device)\n", "        \n", "        optimizer = optim.Adam(model.parameters(), lr = learning_rate) # optimizer to estimate weights and biases (backpropagation)\n", "        \n", "        # Learning rate scheduler, set on min mode to decrease by factor when validation loss stops decreasing                                       \n", "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n", "        \n", "        train_S2S(model,optimizer, loss_fn, trainloader, valloader, scheduler, num_epochs, \n", "                  check_epochs,pred_steps,X_train,y_train, X_val, y_val,\n", "                  tf_ratio, dynamic_tf, training_prediction= 'mixed',device=device,\n", "                  saveas='S2S_out',batch_loss=False)\n", "    else:\n", "        raise ValueError('Model selected is not configured/does not exist. Double check input.')\n\n", "    ######## SAVING ALL RELEVANT DATA ########\n\n", "    ## namedtuple used to store all hyperparams and send as a single arg to save_func\n", "    HyperParams = namedtuple('HyperParams', [\n", "    'input_size', 'hidden_size', 'output_size',\n", "    'pred_steps', 'batch_size', 'learning_rate',\n", "    'num_epochs', 'check_epochs', 'steps_in', 'steps_out', 'tf_ratio', 'dynamic_tf'\n", "        ])\n", "    \n", "    hyper_params = HyperParams(input_size=input_size, hidden_size=hidden_size, output_size=output_size,\n", "    pred_steps=pred_steps, batch_size=batch_size, learning_rate=learning_rate, num_epochs=num_epochs,\n", "    check_epochs=check_epochs, steps_in=steps_in, steps_out=steps_out, tf_ratio=tf_ratio, dynamic_tf=dynamic_tf\n", "    )\n", "    saving_data(windowed_data,hyper_params,model_choice)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == \"__main__\":\n", "    main()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}